# Kafka Best Practices for Go Applications

## Clean Architecture with Kafka

### 1. Infrastructure Decoupling
- **Generic Event Interface**: Use `messaging.Event` interface in infrastructure layer
- **Business Event Types**: Define events in `internal/events/types/`
- **Publisher Abstraction**: Use `internal/events/publisher/` for business layer
- **No Direct Dependencies**: Infrastructure layer should not import business types

### 2. Event Interface Design
```go
// Generic Event interface for infrastructure layer
type Event interface {
    GetTopic() string
    GetEventType() string
    GetUserID() string
    GetRequestID() string
    GetTimestamp() string
}

// Business events implement the interface
func (e *UserRegisteredEvent) GetTopic() string {
    return "user_registered"
}

func (e *UserRegisteredEvent) GetEventType() string {
    return string(e.Type)
}
```

## Kafka Architecture Patterns

### 1. Producer Configuration
```go
// Producer configuration with best practices
config := sarama.NewConfig()
config.Producer.RequiredAcks = sarama.WaitForAll
config.Producer.Retry.Max = 3
config.Producer.Retry.Backoff = 100 * time.Millisecond
config.Producer.Return.Successes = true
config.Producer.Return.Errors = true
config.Producer.Compression = sarama.CompressionSnappy
config.Producer.Idempotent = true
config.Net.MaxOpenRequests = 1
config.Version = sarama.V2_6_0_0
```

### 2. Consumer Configuration
```go
// Consumer configuration with best practices
config := sarama.NewConfig()
config.Consumer.Return.Errors = true
config.Consumer.Offsets.Initial = sarama.OffsetNewest
config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin
config.Consumer.Group.Session.Timeout = 10 * time.Second
config.Consumer.Group.Heartbeat.Interval = 3 * time.Second
config.Consumer.Offsets.AutoCommit.Enable = true
config.Consumer.Offsets.AutoCommit.Interval = 1 * time.Second
config.Version = sarama.V2_6_0_0
```

## Event-Driven Architecture

### 1. Event Definition
```go
// Define strongly typed events in internal/events/types/
type UserRegisteredEvent struct {
    BaseEvent
    Username  string `json:"username"`
    Email     string `json:"email"`
    FirstName string `json:"first_name,omitempty"`
    LastName  string `json:"last_name,omitempty"`
}

// Base event structure
type BaseEvent struct {
    ID        string                 `json:"id"`
    Type      EventType              `json:"type"`
    Source    string                 `json:"source"`
    Timestamp time.Time              `json:"timestamp"`
    Version   string                 `json:"version"`
    RequestID string                 `json:"request_id,omitempty"`
    UserID    string                 `json:"user_id,omitempty"`
    Data      map[string]interface{} `json:"data"`
}
```

### 2. Event Type Constants
```go
// Define event types as constants
const (
    UserRegistered      EventType = "user.registered"
    UserLoggedIn        EventType = "user.logged_in"
    UserPasswordChanged EventType = "user.password_changed"
    UserStatusChanged   EventType = "user.status_changed"
    UserDeleted         EventType = "user.deleted"
    UserUpdated         EventType = "user.updated"
)
```

## Producer Implementation

### 1. Producer Interface (Infrastructure Layer)
```go
type Producer interface {
    PublishUserEvent(ctx context.Context, event interface{}) error
    PublishUserEventAsync(ctx context.Context, event interface{}) error
    Close() error
}
```

### 2. Generic Message Creation
```go
func (p *kafkaProducer) createMessage(eventData interface{}) (*sarama.ProducerMessage, error) {
    // Serialize event data
    jsonData, err := json.Marshal(eventData)
    if err != nil {
        return nil, fmt.Errorf("failed to marshal event data: %w", err)
    }
    
    // Get topic name from Event interface
    var topic string
    if event, ok := eventData.(Event); ok {
        topic = event.GetTopic()
    } else {
        topic = p.config.GetTopicName("user_events")
    }
    
    // Create message
    message := &sarama.ProducerMessage{
        Topic: topic,
        Value: sarama.ByteEncoder(jsonData),
        Key:   sarama.StringEncoder(fmt.Sprintf("%d", time.Now().UnixNano())),
        Headers: []sarama.RecordHeader{
            {Key: []byte("content-type"), Value: []byte("application/json")},
            {Key: []byte("timestamp"), Value: []byte(time.Now().Format(time.RFC3339))},
        },
    }
    
    // Add event type header if Event interface is implemented
    if event, ok := eventData.(Event); ok {
        message.Headers = append(message.Headers, sarama.RecordHeader{
            Key:   []byte("event_type"),
            Value: []byte(event.GetEventType()),
        })
    }
    
    return message, nil
}
```

## Consumer Implementation

### 1. Event Handlers Structure
```go
// Event handlers collection
type EventHandlers struct {
    UserRegistered     *handlers.UserRegisteredHandler
    UserLoggedIn       *handlers.UserLoggedInHandler
    UserPasswordChanged *handlers.UserPasswordChangedHandler
    UserStatusChanged   *handlers.UserStatusChangedHandler
    UserDeleted         *handlers.UserDeletedHandler
    UserUpdated         *handlers.UserUpdatedHandler
}
```

### 2. Message Dispatch
```go
func (c *kafkaConsumer) handleMessage(ctx context.Context, message *sarama.ConsumerMessage) error {
    // Get event type from headers
    eventType := c.getEventType(message.Headers)
    
    switch types.EventType(eventType) {
    case types.UserRegistered:
        var userEvent types.UserRegisteredEvent
        if err := json.Unmarshal(message.Value, &userEvent); err != nil {
            return fmt.Errorf("failed to unmarshal user registered event: %w", err)
        }
        return c.handlers.UserRegistered.Handle(ctx, &userEvent)
        
    case types.UserLoggedIn:
        var userEvent types.UserLoggedInEvent
        if err := json.Unmarshal(message.Value, &userEvent); err != nil {
            return fmt.Errorf("failed to unmarshal user logged in event: %w", err)
        }
        return c.handlers.UserLoggedIn.Handle(ctx, &userEvent)
        
    // Handle other event types...
    default:
        c.logger.Warn("Unknown event type", zap.String("event_type", eventType))
        return nil
    }
}
```

## Event Publishing (Business Layer)

### 1. Publisher Interface
```go
type EventPublisher interface {
    PublishUserRegistered(ctx context.Context, event *types.UserRegisteredEvent) error
    PublishUserLoggedIn(ctx context.Context, event *types.UserLoggedInEvent) error
    PublishUserPasswordChanged(ctx context.Context, event *types.UserPasswordChangedEvent) error
    PublishUserStatusChanged(ctx context.Context, event *types.UserStatusChangedEvent) error
    PublishUserDeleted(ctx context.Context, event *types.UserDeletedEvent) error
    PublishUserUpdated(ctx context.Context, event *types.UserUpdatedEvent) error
    Close() error
}
```

### 2. Kafka Publisher Implementation
```go
type KafkaEventPublisher struct {
    producer messaging.Producer
    logger   *zap.Logger
}

func (p *KafkaEventPublisher) PublishUserRegistered(ctx context.Context, event *types.UserRegisteredEvent) error {
    p.logger.Debug("Publishing user registered event", zap.String("user_id", event.UserID))
    return p.producer.PublishUserEvent(ctx, event)
}
```

### 3. Event Service Integration
```go
func (s *EventService) PublishUserRegistered(ctx context.Context, userID string, username, email string) error {
    event := &types.UserRegisteredEvent{
        BaseEvent: types.NewBaseEvent(
            types.UserRegistered,
            "user-center",
            s.getRequestID(ctx),
            userID,
        ),
        Username: username,
        Email:    email,
    }
    
    return s.publisher.PublishUserRegistered(ctx, event)
}
```

## Best Practices

### 1. Infrastructure Decoupling
- Use generic interfaces in infrastructure layer
- Business events implement infrastructure interfaces
- No direct imports of business types in infrastructure
- Maintain clean separation of concerns

### 2. Event Design
- Each event type has its own topic
- Events contain business data, not infrastructure details
- Use consistent event structure across all events
- Include proper metadata (ID, timestamp, request ID)

### 3. Error Handling
- Handle serialization errors gracefully
- Log failed message processing
- Don't let infrastructure errors affect business flow
- Use proper error wrapping for context

### 4. Testing
- Mock event publishers for business logic tests
- Test event handlers independently
- Use dependency injection for easy mocking
- Test infrastructure components separately

### 5. Monitoring
- Log event publishing and consumption
- Monitor message processing latency
- Track failed message processing
- Use structured logging with context
